{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"vscode":{"interpreter":{"hash":"23df70d482b35e79876ee24f72a1adf1a99bbd330d7b589c7509f8cde77b70e2"}}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# SpineNet Lumbar Grading Example\n\nLast edited: 05/07/2022\n\nThis notebook shows an example of using SpineNet to grade a typical T2 lumbar scan\non CUDA-enabled hardware. Note that it is also possible to run SpineNet on a CPU\nonly (however, this will be slower).\n\n\n## 01. Loading In SpineNet + Data","metadata":{}},{"cell_type":"code","source":"import sys\nimport os\nfrom pathlib import Path\nsys.path.insert(0, str(Path(os.getcwd()).parent)) # Add parent directory to path. This shouldn't be needed if SpineNet is pip-installed\n\n\n\nimport spinenet\nfrom spinenet import SpineNet, download_example_scan\nfrom spinenet.io import load_dicoms_from_folder\n\n# download example scans \nos.makedirs('example_scans', exist_ok=True)\n\n# download_example_scan('t2_lumbar_scan_1', file_path='example_scans')\n# or use the other example scan available\nscan_name = 't2_lumbar_scan_2'\n\nexample_scan_folder = f'./example_scans'\ndownload_example_scan(scan_name, file_path=example_scan_folder)\n\n\n# download weights from server. This may take a minute or two.\n# You do not need to run this line if weights have already been downloaded.\nspinenet.download_weights(verbose=True, force=False)\n\n# load in spinenet. Replace device with 'cpu' if you are not using a CUDA-enabled machine.\nspnt = SpineNet(device='cuda:0', verbose=True)\n\n\n\n\n# metadata to be overwritten in the scan - useful if certain important values are missing from some/all dicom files\n# in this case, slice thickness and image orientation are missing from the dicom files and so we add false values\n# of 2mm and a sagittal orientation code ([0,1,0,0,0,1]). \n# Do not overwrite this metadata if it already exists in the dicom files being used.\noverwrite_dict = {'SliceThickness': [2], 'ImageOrientationPatient': [0, 1, 0, 0, 0, -1]}\n\n\n# loads in a dicom from the example scan folder.\n# if set, the `require_extensions` flag requires that files end with `.dcm`\nscan = load_dicoms_from_folder(f\"{example_scan_folder}/{scan_name}\", require_extensions=False, metadata_overwrites=overwrite_dict)\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.317614Z","iopub.execute_input":"2024-07-28T15:20:14.318041Z","iopub.status.idle":"2024-07-28T15:20:14.654549Z","shell.execute_reply.started":"2024-07-28T15:20:14.318008Z","shell.execute_reply":"2024-07-28T15:20:14.652262Z"},"trusted":true},"execution_count":1,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 8\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpathlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Path\n\u001b[1;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mstr\u001b[39m(Path(os\u001b[38;5;241m.\u001b[39mgetcwd())\u001b[38;5;241m.\u001b[39mparent)) \u001b[38;5;66;03m# Add parent directory to path. This shouldn't be needed if SpineNet is pip-installed\u001b[39;00m\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mspinenet\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspinenet\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SpineNet, download_example_scan\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mspinenet\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_dicoms_from_folder\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'spinenet'"],"ename":"ModuleNotFoundError","evalue":"No module named 'spinenet'","output_type":"error"}]},{"cell_type":"markdown","source":"## 02. Visualize Scan Slices\n\nShow each slice from the sagittal T2 lumbar scan and print out metadata information.","metadata":{}},{"cell_type":"code","source":"print(f'Scan has {scan.volume.shape[-1]} sagittal slices, of dimension {scan.volume.shape[0]}x{scan.volume.shape[1]} ({scan.pixel_spacing} mm pixel spacing) and {scan.slice_thickness} mm slice thickness.')\n\n\nimport matplotlib.pyplot as plt\nfig = plt.figure(figsize=(8,8))\n\n# show each sagittal slice\nfor slice_idx in range(scan.volume.shape[-1]):\n    ax = fig.add_subplot(4,3,slice_idx+1)\n    ax.imshow(scan.volume[:,:,slice_idx], cmap='gray')\n    ax.set_title(f'Slice {slice_idx+1}')\n    ax.axis('off')\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.655648Z","iopub.status.idle":"2024-07-28T15:20:14.656099Z","shell.execute_reply.started":"2024-07-28T15:20:14.655901Z","shell.execute_reply":"2024-07-28T15:20:14.655920Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 03. Detect Vertebrae\nUse SpineNet to detect vertebrae and then show the detections in slices.","metadata":{}},{"cell_type":"code","source":"# detect and identify vertebrae in scan. Note that pixel spacing information is required \n# so SpineNet knows what size to split patches into.\nvert_dicts = spnt.detect_vb(scan.volume, scan.pixel_spacing)\n\nprint(f'{len(vert_dicts)} vertebrae detected; {[vert_dict[\"predicted_label\"] for vert_dict in vert_dicts]}')\n\n\n# visualize vertebrae detections in slices \nfrom matplotlib.patches import Polygon \nimport numpy as np\nfig = plt.figure(figsize=(8,8))\nfor slice_idx in range(scan.volume.shape[-1]):\n    ax = fig.add_subplot(4,3,slice_idx+1)\n    ax.imshow(scan.volume[:,:,slice_idx], cmap='gray')\n    ax.set_title(f'Slice {slice_idx+1}')\n    ax.axis('off')\n    for vert_dict in vert_dicts:\n        if slice_idx in vert_dict['slice_nos']:\n            poly_idx = int(vert_dict['slice_nos'].index(slice_idx))\n            poly = np.array(vert_dict['polys'][poly_idx])\n            ax.add_patch(Polygon(poly, ec='y',fc='none'))\n            ax.text(np.mean(poly[:,0]), np.mean(poly[:,1]), vert_dict['predicted_label'],c='y', ha='center',va='center')\n\nfig.suptitle('Detected Vertebrae (all slices)')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.657274Z","iopub.status.idle":"2024-07-28T15:20:14.657823Z","shell.execute_reply.started":"2024-07-28T15:20:14.657536Z","shell.execute_reply":"2024-07-28T15:20:14.657558Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 04. Show vertebrae detections in the mid sagittal slice","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.patches import Polygon\n# plot mid sagittal slice and detected vertebrae\nplt.figure(figsize=(5,5))\nplt.imshow(scan.volume[:,:,scan.volume.shape[-1]//2], cmap='gray')\nfor idx, vert_dict in enumerate(vert_dicts):\n    if scan.volume.shape[-1]//2 in vert_dict['slice_nos']:\n        poly = np.array(vert_dict['polys'][vert_dict['slice_nos'].index(scan.volume.shape[-1]//2)])\n        plt.gca().add_patch(Polygon(poly, fc='none', ec='y'))\n        plt.text(np.mean(poly[:,0]), np.mean(poly[:,1]), vert_dict['predicted_label'], color='y',fontsize=20, va='center', ha='center')\n    else:\n        continue\n\nplt.axis('off')\nplt.title('Detected Vertebrae (Mid Sagittal Slice)')\nplt.show()\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.659394Z","iopub.status.idle":"2024-07-28T15:20:14.659946Z","shell.execute_reply.started":"2024-07-28T15:20:14.659650Z","shell.execute_reply":"2024-07-28T15:20:14.659693Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 05. Perform grading of T2 scans for common radiological conditions\n\nSince this is a T2 sagittal lumbar scan, SpineNet can be used to perform radiological grading for several common spinal degenerative conditions. Note that this is trained on IVDs from T12/L5 to L5/S1 so may not be accurate for vertebrae outside this range.","metadata":{}},{"cell_type":"code","source":"# extract IVDs using the detections from the previous stage.\nivd_dicts = spnt.get_ivds_from_vert_dicts(vert_dicts, scan.volume)\n\n# grade IVDs - note that this is only validated on IVDs from L5/S1 to T12/L5 vertebrae.\n# IVDs gradings are output as a pandas dictionary. For information on the grading schemes used, see http://zeus.robots.ox.ac.uk/spinenet2/\nivd_grades = spnt.grade_ivds(ivd_dicts)\nivd_grades.head(len(ivd_dicts))\n\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.661602Z","iopub.status.idle":"2024-07-28T15:20:14.662147Z","shell.execute_reply.started":"2024-07-28T15:20:14.661883Z","shell.execute_reply":"2024-07-28T15:20:14.661905Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"results_folder = './results'\nos.makedirs(results_folder, exist_ok=True)\n\nivd_grades.to_csv(f\"{results_folder}/{scan_name}_ivd_grades.csv\")\n","metadata":{"execution":{"iopub.status.busy":"2024-07-28T15:20:14.663999Z","iopub.status.idle":"2024-07-28T15:20:14.664524Z","shell.execute_reply.started":"2024-07-28T15:20:14.664256Z","shell.execute_reply":"2024-07-28T15:20:14.664278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install keras-core","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:35:21.089865Z","iopub.execute_input":"2024-08-01T11:35:21.090834Z","iopub.status.idle":"2024-08-01T11:35:39.833322Z","shell.execute_reply.started":"2024-08-01T11:35:21.090763Z","shell.execute_reply":"2024-08-01T11:35:39.831107Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"Collecting keras-core\n  Downloading keras_core-0.1.7-py3-none-any.whl.metadata (4.3 kB)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.10.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\nDownloading keras_core-0.1.7-py3-none-any.whl (950 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m950.8/950.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n\u001b[?25hInstalling collected packages: keras-core\nSuccessfully installed keras-core-0.1.7\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install keras-core\n!pip install wurlitzer\n!pip install tensorflow==2.15.0  # Downgrade TensorFlow if necessary\n!pip install tensorflow-decision-forests\n!pip check  # Optional: Check for any remaining conflicts","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:46:38.159444Z","iopub.execute_input":"2024-08-01T11:46:38.161328Z","iopub.status.idle":"2024-08-01T11:48:59.828567Z","shell.execute_reply.started":"2024-08-01T11:46:38.161272Z","shell.execute_reply":"2024-08-01T11:48:59.826742Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Requirement already satisfied: keras-core in /opt/conda/lib/python3.10/site-packages (0.1.7)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.4.0)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from keras-core) (1.26.4)\nRequirement already satisfied: rich in /opt/conda/lib/python3.10/site-packages (from keras-core) (13.7.0)\nRequirement already satisfied: namex in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.0.8)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.10/site-packages (from keras-core) (3.10.0)\nRequirement already satisfied: dm-tree in /opt/conda/lib/python3.10/site-packages (from keras-core) (0.1.8)\nRequirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (3.0.0)\nRequirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from rich->keras-core) (2.17.2)\nRequirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich->keras-core) (0.1.2)\nRequirement already satisfied: wurlitzer in /opt/conda/lib/python3.10/site-packages (3.1.1)\nCollecting tensorflow==2.15.0\n  Downloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.4 kB)\nRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.4.0)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (16.0.6)\nCollecting ml-dtypes~=0.2.0 (from tensorflow==2.15.0)\n  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\nRequirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.26.4)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (69.0.3)\nRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.16.0)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (1.60.0)\nCollecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.0)\n  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.0) (2.15.0)\nCollecting keras<2.16,>=2.15.0 (from tensorflow==2.15.0)\n  Using cached keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.0) (0.42.0)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow==2.15.0) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.0) (3.2.2)\nDownloading tensorflow-2.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hUsing cached keras-2.15.0-py3-none-any.whl (1.7 MB)\nDownloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m\n\u001b[?25hDownloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hInstalling collected packages: ml-dtypes, keras, tensorboard, tensorflow\n  Attempting uninstall: ml-dtypes\n    Found existing installation: ml-dtypes 0.4.0\n    Uninstalling ml-dtypes-0.4.0:\n      Successfully uninstalled ml-dtypes-0.4.0\n  Attempting uninstall: keras\n    Found existing installation: keras 3.4.1\n    Uninstalling keras-3.4.1:\n      Successfully uninstalled keras-3.4.1\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.17.0\n    Uninstalling tensorboard-2.17.0:\n      Successfully uninstalled tensorboard-2.17.0\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.17.0\n    Uninstalling tensorflow-2.17.0:\n      Successfully uninstalled tensorflow-2.17.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow-text 2.17.0 requires tensorflow<2.18,>=2.17.0, but you have tensorflow 2.15.0 which is incompatible.\ntensorstore 0.1.60 requires ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0 which is incompatible.\ntf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0 which is incompatible.\ntf-models-official 2.17.0 requires tensorflow~=2.17.0, but you have tensorflow 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed keras-2.15.0 ml-dtypes-0.2.0 tensorboard-2.15.2 tensorflow-2.15.0\nRequirement already satisfied: tensorflow-decision-forests in /opt/conda/lib/python3.10/site-packages (1.8.1)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (1.26.4)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (2.2.2)\nRequirement already satisfied: tensorflow~=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (2.15.0)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (1.16.0)\nRequirement already satisfied: absl-py in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (1.4.0)\nRequirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (0.42.0)\nRequirement already satisfied: wurlitzer in /opt/conda/lib/python3.10/site-packages (from tensorflow-decision-forests) (3.1.1)\nRequirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (1.6.3)\nRequirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (24.3.25)\nRequirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (0.5.4)\nRequirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (0.2.0)\nRequirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (3.10.0)\nRequirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (16.0.6)\nRequirement already satisfied: ml-dtypes~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (0.2.0)\nRequirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (3.3.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (21.3)\nRequirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (3.20.3)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (69.0.3)\nRequirement already satisfied: termcolor>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (2.4.0)\nRequirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (4.9.0)\nRequirement already satisfied: wrapt<1.15,>=1.11.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (1.14.1)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (0.35.0)\nRequirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (1.60.0)\nRequirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (2.15.2)\nRequirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (2.15.0)\nRequirement already satisfied: keras<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow~=2.15.0->tensorflow-decision-forests) (2.15.0)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests) (2023.3.post1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->tensorflow-decision-forests) (2023.4)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (2.26.1)\nRequirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (1.2.0)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (3.5.2)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (2.32.3)\nRequirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (0.7.2)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (3.0.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->tensorflow~=2.15.0->tensorflow-decision-forests) (3.1.1)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (0.3.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (1.3.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (3.6)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (2024.2.2)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (2.1.3)\nRequirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (0.5.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow~=2.15.0->tensorflow-decision-forests) (3.2.2)\naiobotocore 2.13.0 has requirement aiohttp<4.0.0,>=3.9.2, but you have aiohttp 3.9.1.\napache-beam 2.46.0 has requirement dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8.\napache-beam 2.46.0 has requirement numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4.\napache-beam 2.46.0 has requirement pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0.\nbeatrix-jupyterlab 2023.128.151533 has requirement jupyterlab~=3.6.0, but you have jupyterlab 4.2.1.\nboto3 1.26.100 has requirement botocore<1.30.0,>=1.29.100, but you have botocore 1.34.106.\ncloud-tpu-client 0.10 has requirement google-api-python-client==1.8.0, but you have google-api-python-client 2.131.0.\nconda 24.5.0 has requirement packaging>=23.0, but you have packaging 21.3.\ngoogle-cloud-aiplatform 0.6.0a1 has requirement google-api-core[grpc]<2.0.0dev,>=1.22.2, but you have google-api-core 2.11.1.\ngoogle-cloud-automl 1.0.1 has requirement google-api-core[grpc]<2.0.0dev,>=1.14.0, but you have google-api-core 2.11.1.\njupyterlab 4.2.1 has requirement jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1.\njupyterlab-lsp 5.1.0 has requirement jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1.\nkfp 2.5.0 has requirement google-cloud-storage<3,>=2.2.1, but you have google-cloud-storage 1.44.0.\nlibpysal 4.9.2 has requirement packaging>=22, but you have packaging 21.3.\nlibpysal 4.9.2 has requirement shapely>=2.0.1, but you have shapely 1.8.5.post1.\nmomepy 0.7.0 has requirement shapely>=2, but you have shapely 1.8.5.post1.\nosmnx 1.9.3 has requirement shapely>=2.0, but you have shapely 1.8.5.post1.\npytoolconfig 1.3.1 has requirement packaging>=23.2, but you have packaging 21.3.\nspopt 0.6.0 has requirement shapely>=2.0.1, but you have shapely 1.8.5.post1.\ntensorflow-text 2.17.0 has requirement tensorflow<2.18,>=2.17.0, but you have tensorflow 2.15.0.\ntensorstore 0.1.60 has requirement ml-dtypes>=0.3.1, but you have ml-dtypes 0.2.0.\ntextblob 0.18.0.post0 has requirement nltk>=3.8, but you have nltk 3.2.4.\ntf-keras 2.17.0 has requirement tensorflow<2.18,>=2.17, but you have tensorflow 2.15.0.\ntf-models-official 2.17.0 has requirement tensorflow~=2.17.0, but you have tensorflow 2.15.0.\nxarray 2024.5.0 has requirement packaging>=23.1, but you have packaging 21.3.\nydata-profiling 4.6.4 has requirement numpy<1.26,>=1.16.0, but you have numpy 1.26.4.\nydata-profiling 4.6.4 has requirement typeguard<5,>=4.1.2, but you have typeguard 2.13.3.\n","output_type":"stream"}]},{"cell_type":"code","source":"!git clone --depth 1 https://github.com/tensorflow/models","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:49:08.572588Z","iopub.execute_input":"2024-08-01T11:49:08.573104Z","iopub.status.idle":"2024-08-01T11:49:14.580786Z","shell.execute_reply.started":"2024-08-01T11:49:08.573066Z","shell.execute_reply":"2024-08-01T11:49:14.579241Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"Cloning into 'models'...\nremote: Enumerating objects: 4245, done.\u001b[K\nremote: Counting objects: 100% (4245/4245), done.\u001b[K\nremote: Compressing objects: 100% (3235/3235), done.\u001b[K\nremote: Total 4245 (delta 1193), reused 2123 (delta 939), pack-reused 0\u001b[K\nReceiving objects: 100% (4245/4245), 48.86 MiB | 32.64 MiB/s, done.\nResolving deltas: 100% (1193/1193), done.\n","output_type":"stream"}]},{"cell_type":"code","source":"import os","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:50:03.095416Z","iopub.execute_input":"2024-08-01T11:50:03.095950Z","iopub.status.idle":"2024-08-01T11:50:03.103839Z","shell.execute_reply.started":"2024-08-01T11:50:03.095902Z","shell.execute_reply":"2024-08-01T11:50:03.101774Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:50:37.879140Z","iopub.execute_input":"2024-08-01T11:50:37.881010Z","iopub.status.idle":"2024-08-01T11:50:37.891501Z","shell.execute_reply.started":"2024-08-01T11:50:37.880955Z","shell.execute_reply":"2024-08-01T11:50:37.890000Z"},"trusted":true},"execution_count":14,"outputs":[{"execution_count":14,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working'"},"metadata":{}}]},{"cell_type":"code","source":"os.chdir(\"/kaggle/working/models/research\")","metadata":{"execution":{"iopub.status.busy":"2024-08-01T11:50:54.412689Z","iopub.execute_input":"2024-08-01T11:50:54.413179Z","iopub.status.idle":"2024-08-01T11:50:54.420852Z","shell.execute_reply.started":"2024-08-01T11:50:54.413144Z","shell.execute_reply":"2024-08-01T11:50:54.419250Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"!cd models/research && protoc object_detection/protos/*.proto --python_out=.","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:09:11.348704Z","iopub.execute_input":"2024-08-01T12:09:11.349222Z","iopub.status.idle":"2024-08-01T12:09:12.678708Z","shell.execute_reply.started":"2024-08-01T12:09:11.349138Z","shell.execute_reply":"2024-08-01T12:09:12.676460Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"os.getcwd()","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:08:53.472114Z","iopub.execute_input":"2024-08-01T12:08:53.472640Z","iopub.status.idle":"2024-08-01T12:08:53.483782Z","shell.execute_reply.started":"2024-08-01T12:08:53.472597Z","shell.execute_reply":"2024-08-01T12:08:53.482253Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"'/kaggle/working/models/research'"},"metadata":{}}]},{"cell_type":"code","source":"%cd ..","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:09:09.334717Z","iopub.execute_input":"2024-08-01T12:09:09.335263Z","iopub.status.idle":"2024-08-01T12:09:09.345939Z","shell.execute_reply.started":"2024-08-01T12:09:09.335225Z","shell.execute_reply":"2024-08-01T12:09:09.343809Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"/kaggle/working\n","output_type":"stream"}]},{"cell_type":"code","source":"os.environ['PYTHONPATH'] += \":/kaggle/working/models:/kaggle/working/models/research:/kaggle/working/models/research/slim\"","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:09:34.203179Z","iopub.execute_input":"2024-08-01T12:09:34.203709Z","iopub.status.idle":"2024-08-01T12:09:34.211770Z","shell.execute_reply.started":"2024-08-01T12:09:34.203670Z","shell.execute_reply":"2024-08-01T12:09:34.210073Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"code","source":"!ls models/research/object_detection/protos","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:09:44.961261Z","iopub.execute_input":"2024-08-01T12:09:44.962726Z","iopub.status.idle":"2024-08-01T12:09:46.161718Z","shell.execute_reply.started":"2024-08-01T12:09:44.962659Z","shell.execute_reply":"2024-08-01T12:09:46.160139Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"__init__.py\t\t\t       input_reader_pb2.py\n__pycache__\t\t\t       keypoint_box_coder.proto\nanchor_generator.proto\t\t       keypoint_box_coder_pb2.py\nanchor_generator_pb2.py\t\t       losses.proto\nargmax_matcher.proto\t\t       losses_pb2.py\nargmax_matcher_pb2.py\t\t       matcher.proto\nbipartite_matcher.proto\t\t       matcher_pb2.py\nbipartite_matcher_pb2.py\t       mean_stddev_box_coder.proto\nbox_coder.proto\t\t\t       mean_stddev_box_coder_pb2.py\nbox_coder_pb2.py\t\t       model.proto\nbox_predictor.proto\t\t       model_pb2.py\nbox_predictor_pb2.py\t\t       multiscale_anchor_generator.proto\ncalibration.proto\t\t       multiscale_anchor_generator_pb2.py\ncalibration_pb2.py\t\t       optimizer.proto\ncenter_net.proto\t\t       optimizer_pb2.py\ncenter_net_pb2.py\t\t       pipeline.proto\neval.proto\t\t\t       pipeline_pb2.py\neval_pb2.py\t\t\t       post_processing.proto\nfaster_rcnn.proto\t\t       post_processing_pb2.py\nfaster_rcnn_box_coder.proto\t       preprocessor.proto\nfaster_rcnn_box_coder_pb2.py\t       preprocessor_pb2.py\nfaster_rcnn_pb2.py\t\t       region_similarity_calculator.proto\nflexible_grid_anchor_generator.proto   region_similarity_calculator_pb2.py\nflexible_grid_anchor_generator_pb2.py  square_box_coder.proto\nfpn.proto\t\t\t       square_box_coder_pb2.py\nfpn_pb2.py\t\t\t       ssd.proto\ngraph_rewriter.proto\t\t       ssd_anchor_generator.proto\ngraph_rewriter_pb2.py\t\t       ssd_anchor_generator_pb2.py\ngrid_anchor_generator.proto\t       ssd_pb2.py\ngrid_anchor_generator_pb2.py\t       string_int_label_map.proto\nhyperparams.proto\t\t       string_int_label_map_pb2.py\nhyperparams_pb2.py\t\t       target_assigner.proto\nimage_resizer.proto\t\t       target_assigner_pb2.py\nimage_resizer_pb2.py\t\t       train.proto\ninput_reader.proto\t\t       train_pb2.py\n","output_type":"stream"}]},{"cell_type":"code","source":"from object_detection.builders import model_builder","metadata":{"execution":{"iopub.status.busy":"2024-08-01T12:09:58.096984Z","iopub.execute_input":"2024-08-01T12:09:58.098275Z","iopub.status.idle":"2024-08-01T12:09:59.732862Z","shell.execute_reply.started":"2024-08-01T12:09:58.098208Z","shell.execute_reply":"2024-08-01T12:09:59.731019Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}